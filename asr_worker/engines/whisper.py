import logging
import os
import re
from .base import ASREngine, format_timestamp

logger = logging.getLogger("ASR Worker")

class WhisperEngine(ASREngine):
    def __init__(self, model_path=None, model_name=None):
        from config import get_config, get_engine_config
        cfg = get_config()
        ecfg = get_engine_config("whisper")

        # Priority: constructor arg > config > env > default
        self.model_name = model_name or ecfg.get("model_name", "large-v3-turbo")
        self.model_path = model_path or ecfg.get("download_root") or os.getenv("WHISPER_MODEL_PATH")
        device_cfg = cfg.get("device", "cuda:0")

        logger.info(f"ğŸš€ Loading Whisper: {self.model_name} from {self.model_path}")
        try:
            import whisper
        except ImportError:
            raise ImportError("Whisper dependency 'openai-whisper' not installed.")

        if self.model_path:
            os.makedirs(self.model_path, exist_ok=True)

        # Determine device (respect config, fallback to auto-detect)
        import torch
        if device_cfg.startswith("cuda") and not torch.cuda.is_available():
            device = "cpu"
        else:
            device = device_cfg.split(":")[0]  # whisper uses "cuda" not "cuda:0"
        logger.info(f"ğŸ–¥ï¸ Using Device: {device}")

        self.model = whisper.load_model(self.model_name, download_root=self.model_path, device=device)

    def predict(self, audio_path: str, language: str = "zh", initial_prompt: str = None, check_cancel_func=None):
        logger.info(f"ğŸ“‚ [Whisper] Processing: {audio_path}")
        
        if check_cancel_func: check_cancel_func()
        audio_data = self.load_audio(audio_path)
        
        if check_cancel_func: check_cancel_func()
        
        result = self.model.transcribe(
            audio_data, 
            language=language or "zh",
            initial_prompt=initial_prompt or "è¿™æ˜¯ä¸€æ®µæ™®é€šè¯å½•éŸ³ã€‚è¯·åœ¨è½¬å†™æ—¶ä½¿ç”¨æ ‡å‡†çš„ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œä¾‹å¦‚ï¼šé€—å·ï¼Œå¥å·ã€‚",
            beam_size=5
        )
        
        text = result["text"]
        
        if check_cancel_func: check_cancel_func()

        # Post-processing
        if re.search(r'[\u4e00-\u9fff]', text):
            text = text.replace(",", "ï¼Œ").replace("?", "ï¼Ÿ").replace("!", "ï¼")
            text = re.sub(r'(?<=[\u4e00-\u9fff])\.', 'ã€‚', text)
            text = re.sub(r'\.(?=\s|$)', 'ã€‚', text)
            
        return text

    def generate_srt(self, audio_path: str, language: str = "zh", initial_prompt: str = None, check_cancel_func=None) -> str:
        logger.info(f"ğŸ“‚ [Whisper] Generating SRT: {audio_path}")
        
        if check_cancel_func: check_cancel_func()
        audio_data = self.load_audio(audio_path)
        
        if check_cancel_func: check_cancel_func()
        
        result = self.model.transcribe(
            audio_data, 
            language=language or "zh",
            initial_prompt=initial_prompt or "è¿™æ˜¯ä¸€æ®µæ™®é€šè¯å½•éŸ³ã€‚è¯·åœ¨è½¬å†™æ—¶ä½¿ç”¨æ ‡å‡†çš„ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œä¾‹å¦‚ï¼šé€—å·ï¼Œå¥å·ã€‚",
            beam_size=5
        )
        
        srt_content = ""
        segments = result.get('segments', [])
        
        for i, seg in enumerate(segments):
            if check_cancel_func: check_cancel_func()
            start = format_timestamp(seg['start'])
            end = format_timestamp(seg['end'])
            text = seg['text'].strip()
            
            if re.search(r'[\u4e00-\u9fff]', text):
                text = text.replace(",", "ï¼Œ").replace("?", "ï¼Ÿ").replace("!", "ï¼")
                text = re.sub(r'(?<=[\u4e00-\u9fff])\.', 'ã€‚', text)
                text = re.sub(r'\.(?=\s|$)', 'ã€‚', text)
                
            srt_content += f"{i+1}\n{start} --> {end}\n{text}\n\n"
            
        return srt_content
